{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAOXDVQqgbIfkxVty2nfh+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvyWang845/Project-Practice-3-CNN-Image-Classification/blob/main/1_CNN_ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0KLHWqPa4ju"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torch"
      ],
      "metadata": {
        "id": "0HT3nQZkcO3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # PyTorch\n",
        "from torchvision import datasets # Datasets module\n",
        "import torchvision.transforms as transforms # Image Transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler # Sampler"
      ],
      "metadata": {
        "id": "CQZ8tYRpdVim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "CxI_f3pHdjWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# choose the training and test datasets\n",
        "train_data = datasets.MNIST(root='data', train=True,    # train=true => training set\n",
        "                                   download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='data', train=False,    # train=false => test set\n",
        "                                  download=True, transform=transform)"
      ],
      "metadata": {
        "id": "kM_BIf3LeJnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain training indices that will be used for validation\n",
        "\n",
        "# 1. Create a list of indices of the training data\n",
        "num_train = len(train_data)\n",
        "print('num_train = len(train_data) ==> ', num_train)\n",
        "indices = list(range(num_train))\n",
        "print('len(indices) ==>', len(indices))"
      ],
      "metadata": {
        "id": "K7evTG2cfmKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Randomly Shuffle those indices\n",
        "np.random.shuffle(indices)"
      ],
      "metadata": {
        "id": "iYNNan08f3bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Slice the indices in 80-20 split\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2 # ie Train Set divided into two parts\n",
        "                 # 80% Train 20% Validation\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "print('len(train_idx) ==> ', len(train_idx))\n",
        "print('len(valid_idx) ==> ', len(valid_idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f39nF0D4gQLw",
        "outputId": "dfe7b41b-3986-4ffc-ddef-6cf333305ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_idx) ==>  48000\n",
            "len(valid_idx) ==>  12000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define samplers for obtaining training and validation batches\n",
        "# remember train_idx and valid_idx were the indices that we shuffled above\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# prepare dataloaders\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0 # do not modify\n",
        "# how many samples per batch to load\n",
        "batch_size = 64 # ie 20 images per batch\n",
        "\n",
        "# Training Set\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, \\\n",
        "                                           batch_size=batch_size, \\\n",
        "                                           sampler=train_sampler, \\\n",
        "                                           num_workers=num_workers)\n",
        "# Validation Set\n",
        "valid_loader = torch.utils.data.DataLoader(dataset=train_data, \\\n",
        "                                           batch_size=batch_size, \\\n",
        "                                           sampler=valid_sampler, \\\n",
        "                                           num_workers=num_workers)\n",
        "# Test Set\n",
        "# Notice we have not used a 'sampler' here as it was not required\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data, \\\n",
        "                                          batch_size=batch_size, \\\n",
        "                                          num_workers=num_workers)"
      ],
      "metadata": {
        "id": "nNXchxSZhDLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn # nn module contains all the layers\n",
        "import torch.nn.functional as F # same as nn, but a little different"
      ],
      "metadata": {
        "id": "T25JraH0ihVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our CNN based neural architecture\n",
        "# Let's build a simple one with only Convolutional, Linear\n",
        "# and dropout layers\n",
        "class MNISTModel1(nn.Module):\n",
        "    # Here we define the neural architecture\n",
        "    def __init__(self):\n",
        "        super(MNISTModel1, self).__init__() # Initialize the nn module\n",
        "\n",
        "        # Convolutional Layers\n",
        "        # What shape/dimensions the first layer is going to see?\n",
        "        # Do we need to have some padding for a kernel_size = 3?\n",
        "        # Input Features = 1 x 28 x 28\n",
        "        # Output Features = ???\n",
        "        # Shape of a Convolutional Layer = (W - K + 2P)\n",
        "        #                                  ------------ + 1\n",
        "        #                                       S\n",
        "        # where,\n",
        "        #       W = Width/Height of previous layer = 28\n",
        "        #       K = Filter Size = 3\n",
        "        #       P = Padding = 0\n",
        "        #       S = Stride = 1(default)\n",
        "        # Therefore,\n",
        "        #           if padding = 0\n",
        "        #           Output Shape = ((28 - 3 + 2*0)/1)+1 = 26\n",
        "        # We want the dimensions to stay the same so that there is no\n",
        "        # loss of information when performing the convolution.\n",
        "        # Hence,\n",
        "        #       if padding = 1\n",
        "        #       Output Shape = ((28 - 3 + 2*1)/1)+1 = 28\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, \\\n",
        "                               stride=1, padding=1) # Output Features = 8 x 28 x 28\n",
        "        # Input Features = 8 x 28 x 28\n",
        "        # Output Features = 16 x 28 x 28 | ((28 - 3 + 2*1)/1)+1 = 28\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, \\\n",
        "                               stride=1, padding=1)\n",
        "\n",
        "        # Linear Layers\n",
        "        # What shape the first linear layer is going see?\n",
        "        # What are the total number of features given out by conv2?\n",
        "        # Features = 16 x 28 x 28 = 12544\n",
        "        # Therefore,\n",
        "        self.linear1 = nn.Linear(in_features=12544, out_features=256)\n",
        "        self.linear2 = nn.Linear(in_features=256, out_features=64)\n",
        "        # Last linear layer should output 10 features as we are\n",
        "        # Classifying the images in 10 categories\n",
        "        self.linear3 = nn.Linear(in_features=64, out_features=10)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(p=0.25)\n",
        "\n",
        "    # Here we define the 'forward behaviour' of our neural architecture\n",
        "    def forward(self, image_batch):\n",
        "        # This is also the place where we add ACTIVATION functions\n",
        "        image_batch = F.relu(input=self.conv1(image_batch))\n",
        "        image_batch = F.relu(input=self.conv2(image_batch))\n",
        "\n",
        "        # Remember that when passing image_batch through the Linear layers,\n",
        "        # PyTorch expects:\n",
        "        # >>> torch.Size([12, 256]) -> example values\n",
        "            # 2d: [batch_size, num_features (aka: C * H * W)]\n",
        "            # use for nn.Linear() input.\n",
        "        # Therefore, we need to 'flatten' image_batch\n",
        "        # image_batch = image_batch.view(batch_size, -1) --> batch size ???\n",
        "        flat_image_batch = image_batch.view(image_batch.shape[0], -1)\n",
        "        flat_image_batch = F.relu(input=self.linear1(flat_image_batch))\n",
        "        # Let's add the dropout too\n",
        "        flat_image_batch = self.dropout(F.relu(input=self.linear2(flat_image_batch)))\n",
        "        # Final Layer of the network\n",
        "        flat_image_batch = F.relu(input=self.linear3(flat_image_batch))\n",
        "        # The output from the final layer is a tensor with 10 'logits'\n",
        "        return flat_image_batch"
      ],
      "metadata": {
        "id": "MrcInrJ4jdRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "0MuU0JIprnzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can make the use of torchsummary library here to figure\n",
        "# if we have done something wrong\n",
        "\n",
        "# But first we need to tell PyTorch where to 'keep' the model\n",
        "# On GPU or on CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('The model will run on', device)\n",
        "\n",
        "# Initialize the model\n",
        "mnist1 = MNISTModel1().to(device)\n",
        "summary(model=mnist1, input_size=(1, 28, 28), batch_size=20) # Summarize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mmDExRArzO6",
        "outputId": "a9b5f586-1c5b-4bc3-b85a-9fe9c7c1479b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model will run on cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [20, 8, 28, 28]              80\n",
            "            Conv2d-2           [20, 16, 28, 28]           1,168\n",
            "            Linear-3                  [20, 256]       3,211,520\n",
            "            Linear-4                   [20, 64]          16,448\n",
            "           Dropout-5                   [20, 64]               0\n",
            "            Linear-6                   [20, 10]             650\n",
            "================================================================\n",
            "Total params: 3,229,866\n",
            "Trainable params: 3,229,866\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 2.93\n",
            "Params size (MB): 12.32\n",
            "Estimated Total Size (MB): 15.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install poutyne"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnj56uy1vLg1",
        "outputId": "75d52a53-5e71-485f-971e-9c493807d417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting poutyne\n",
            "  Downloading Poutyne-1.11-py3-none-any.whl (210 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 51 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 61 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 81 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 102 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 112 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 122 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 133 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 143 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 153 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 163 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 174 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 194 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 204 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 210 kB 12.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from poutyne) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from poutyne) (1.21.6)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.8.1-py3-none-any.whl (408 kB)\n",
            "\u001b[K     |████████████████████████████████| 408 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->poutyne) (4.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics->poutyne) (21.3)\n",
            "Collecting pyDeprecate==0.3.*\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics->poutyne) (3.0.8)\n",
            "Installing collected packages: pyDeprecate, torchmetrics, poutyne\n",
            "Successfully installed poutyne-1.11 pyDeprecate-0.3.2 torchmetrics-0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from poutyne.framework import Model # The core datastructure of poutyne\n",
        "                                    # https://poutyne.org/model.html"
      ],
      "metadata": {
        "id": "kbmtyB8EvIiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim # Optimizer: we need it to train our network"
      ],
      "metadata": {
        "id": "PjF8hcOKukKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A pouytne training loop\n",
        "\n",
        "# A few hyperparamters for the training loop\n",
        "learning_rate = 0.1\n",
        "epochs = 3 #train 3 go-through times\n",
        "\n",
        "def poutyne_train(pytorch_model):\n",
        "\n",
        "    # Select the optimizer and the loss function\n",
        "    optimizer = optim.SGD(pytorch_model.parameters(), lr=learning_rate)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    # Poutyne Model\n",
        "    model = Model(pytorch_model, optimizer, loss_function, batch_metrics=['accuracy'])\n",
        "    # Send the 'Poutyne model' on GPU/CPU whichever is available\n",
        "    model.to(device)\n",
        "    # Train\n",
        "    model.fit_generator(train_loader, valid_loader, epochs=epochs)\n",
        "    # Test\n",
        "    test_loss, test_acc = model.evaluate_generator(test_loader)\n",
        "    print(f'Test:\\n\\tLoss: {test_loss: .3f}\\n\\tAccuracy: {test_acc: .3f}')\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "DST4M-INuXWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poutyne_train(mnist1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAgkcVivvgv4",
        "outputId": "138e94fe-49e4-4c4c-9c39-73ecec234780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/3 Train steps: 750 Val steps: 188 14.60s loss: 0.509408 acc: 83.783333 val_loss: 0.155502 val_acc: 95.175000\n",
            "Epoch: 2/3 Train steps: 750 Val steps: 188 14.20s loss: 0.142731 acc: 95.737500 val_loss: 0.106250 val_acc: 96.833333\n",
            "Epoch: 3/3 Train steps: 750 Val steps: 188 14.28s loss: 0.093152 acc: 97.175000 val_loss: 0.102751 val_acc: 97.025000\n",
            "Test steps: 157 1.80s test_loss: 0.088598 test_acc: 97.100000                                 \n",
            "Test:\n",
            "\tLoss:  0.089\n",
            "\tAccuracy:  97.100\n"
          ]
        }
      ]
    }
  ]
}